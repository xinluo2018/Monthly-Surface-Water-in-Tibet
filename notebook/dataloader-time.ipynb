{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "6f5bb23da6bd6ab87296804a7ae062a565b497c650c7064ca78191dd29b49fd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import config\n",
    "sys.path.append(config.root)\n",
    "import glob\n",
    "import torch\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import threading as td\n",
    "from dataloader.read_preprocess import read_preprocess\n",
    "from dataloader.parallel_loader import parallel_load_dset\n",
    "from dataloader.loader import scene_tensor_dset\n",
    "from queue import Queue\n",
    "from utils.transforms import crop_scales\n",
    "from utils.img_aug import rotate, flip, noise, missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------Data paths-------------- #\n",
    "paths_as = sorted(glob.glob(config.root+'/data/s1_ascend/*'))\n",
    "paths_des = sorted(glob.glob(config.root+'/data/s1_descend/*'))\n",
    "paths_truth = sorted(glob.glob(config.root+'/data/s1_truth/*'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### -----data read & pre-processing------- ###\n",
    "scene_list, truth_list = read_preprocess(paths_as=paths_as,\\\n",
    "                                paths_des=paths_des, paths_truth=paths_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## single process/multiple threads: load 15*num_thread patches\n",
    "# tra_dset = parallel_load_dset(scene_list[0:15], \\\n",
    "#                                 truth_list[0:15], num_thread=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## multiple process\n",
    "tra_dset = scene_tensor_dset(scene_tensor_list=scene_list,\\\n",
    "            truth_tensor_list=truth_list, transforms=config.transforms_tra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 3306, 3632])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time:0.054624080657958984\n"
     ]
    }
   ],
   "source": [
    "def scene2patch(q, scene, truth):\n",
    "    '''pre-processing (e.g., random crop)'''\n",
    "    transforms = [rotate(p=1), flip(p=0.5), noise(p=0.5, \\\n",
    "            std_min=0.001, std_max=0.1), missing(p=0.5, ratio_max = 0.25)]\n",
    "    patches, ptruth = crop_scales(scales=[2048, 512, 256])(scene, truth)\n",
    "    for transform in transforms:\n",
    "        patches, ptruth = transform(patches, ptruth)\n",
    "    ptruth = torch.unsqueeze(ptruth,0)\n",
    "    q.put((patches, ptruth))\n",
    "\n",
    "q = Queue()\n",
    "start = time.time()\n",
    "scene2patch(q, scene_list[0], truth_list[0])\n",
    "print(f'time:{time.time()-start}')\n"
   ]
  },
  {
   "source": [
    "### Multiprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ###!!!!!!!!!Error\n",
    "\n",
    "# print( \"父进程启动id：%d\" % os.getpid())\n",
    "# p1 = mp.Process(target=scene2patch, args=(scene_list[0], truth_list[0]))\n",
    "# p1.start()\n",
    "# p1.join()\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Multi-threading\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 0.901658296585083\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "## define multi-thread job\n",
    "def job(q, scene, truth):    \n",
    "    '''q is Queue'''\n",
    "    transforms = [rotate(p=1), flip(p=0.5), noise(p=0.5, \\\n",
    "            std_min=0.001, std_max=0.1), missing(p=0.5, ratio_max = 0.25)]\n",
    "    '''convert image to patches group'''\n",
    "    patches_group, truth=crop_scales(scales=[2048, 512, 256])(scene, truth)\n",
    "    for transform in transforms:\n",
    "        patches_group, truth = transform(patches_group, truth)\n",
    "    truth = torch.unsqueeze(truth,0)\n",
    "    q.put((patches_group, truth))\n",
    "\n",
    "def parallel_read(scene, truth, num_thread=20):\n",
    "    '''multi-thread reading training data\n",
    "        cooperated with the job function\n",
    "    '''\n",
    "    patch_list, ptruth_list = [], []\n",
    "    q = Queue()\n",
    "    threads = [td.Thread(target=job, args=(q, scene, \\\n",
    "                        truth)) for i in range(num_thread)]\n",
    "    start = [t.start() for t in threads]\n",
    "    join = [t.join() for t in threads]\n",
    "    for i in range(num_thread):\n",
    "        patch, ptruth = q.get()\n",
    "        patch_list.append(patch)\n",
    "        ptruth_list.append(ptruth)\n",
    "    return patch_list, ptruth_list\n",
    "\n",
    "start = time.time()\n",
    "patch_lists, ptruth_lists = [], []\n",
    "for i in range(15):\n",
    "    patch_list, ptruth_list = parallel_read(scene_list[0], truth_list[0], num_thread=1)\n",
    "    patch_lists += patch_list\n",
    "    ptruth_lists += ptruth_list \n",
    "\n",
    "print(f'time: {time.time() - start}')\n",
    "len(patch_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 0.1555314064025879\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define multi-thread job\n",
    "def job(q, scene_list, truth_list):    \n",
    "    '''q is Queue'''\n",
    "    patch_list, ptruth_list = [],[]\n",
    "    transforms = [rotate(p=1), flip(p=0.5), noise(p=0.5, \\\n",
    "            std_min=0.001, std_max=0.1), missing(p=0.5, ratio_max = 0.25)]\n",
    "    '''convert image to patches group'''\n",
    "    zip_data = list(zip(scene_list, truth_list))\n",
    "    for scene, truth in zip_data:\n",
    "        patches_group, truth=crop_scales(scales=[2048, 512, 256])(scene, truth)\n",
    "        for transform in transforms:\n",
    "            patches_group, truth = transform(patches_group, truth)\n",
    "        truth = torch.unsqueeze(truth,0)\n",
    "        patch_list.append(patches_group), ptruth_list.append(truth)\n",
    "    q.put((patch_list, ptruth_list))\n",
    "\n",
    "def parallel_read(scene_list, truth_list, num_thread=20):\n",
    "    '''multi-thread reading training data\n",
    "        cooperated with the job function\n",
    "    '''\n",
    "    patch_lists, ptruth_lists = [], []\n",
    "    q = Queue()\n",
    "    threads = [td.Thread(target=job, args=(q, scene_list, \\\n",
    "                        truth_list)) for i in range(num_thread)]\n",
    "    start = [t.start() for t in threads]\n",
    "    join = [t.join() for t in threads]\n",
    "    for i in range(num_thread):\n",
    "        patch_list, ptruth_list = q.get()\n",
    "        patch_lists += patch_list\n",
    "        ptruth_lists += ptruth_list\n",
    "    return patch_lists, ptruth_lists\n",
    "\n",
    "start = time.time()\n",
    "patches_list, ptruth_list = parallel_read(\\\n",
    "                            scene_list[0:15], truth_list[0:15], num_thread=1000)\n",
    "print('time:{}'.format(time.time()-start))        \n",
    "len(patches_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time:0.0002493858337402344\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tra_loader = torch.utils.data.DataLoader(tra_dset, \\\n",
    "                                batch_size=config.batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:          64301       19865       27848           6       16587       43718\n",
      "Swap:          2047         624        1423\n",
      "time:1.3459398746490479\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for patch, truth in tra_loader:\n",
    "    a = 0\n",
    "!free -m\n",
    "print('time:{}'.format(time.time()-start))        \n"
   ]
  }
 ]
}